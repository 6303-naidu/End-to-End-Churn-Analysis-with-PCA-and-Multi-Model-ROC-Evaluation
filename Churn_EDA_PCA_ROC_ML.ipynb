{"cells": [{"cell_type": "markdown", "metadata": {}, "source": ["# Customer Churn EDA + PCA + ROC (Multi-Model) \u2014 Colab Notebook\n", "\n", "This notebook performs end-to-end analysis on a churn dataset:\n", "- **EDA**: summary stats, missing values, class balance, correlations, distributions.\n", "- **PCA**: dimensionality reduction for visualization and as an optional step in the ML pipeline.\n", "- **ML Models**: Logistic Regression, Random Forest, Gradient Boosting, SVM, KNN, Naive Bayes, MLP.\n", "- **ROC Curves**: One-vs-Rest ROC curves and AUC comparison across models.\n", "- **Model Selection**: pick best model by ROC-AUC and save it.\n", "\n", "> Tip: If you don't have the dataset locally, upload it via the Upload cell or change the path to your file."]}, {"cell_type": "code", "execution_count": null, "metadata": {}, "outputs": [], "source": ["# If you're in Google Colab, uncomment the below to install any missing libs\n", "# !pip install scikit-learn pandas matplotlib seaborn xgboost==1.7.6 imbalanced-learn\n", "\n", "import pandas as pd\n", "import numpy as np\n", "import matplotlib.pyplot as plt\n", "import seaborn as sns\n", "\n", "from sklearn.model_selection import train_test_split\n", "from sklearn.preprocessing import OneHotEncoder, StandardScaler\n", "from sklearn.compose import ColumnTransformer\n", "from sklearn.pipeline import Pipeline\n", "from sklearn.impute import SimpleImputer\n", "from sklearn.decomposition import PCA\n", "from sklearn.metrics import (\n", "    classification_report, confusion_matrix, roc_auc_score,\n", "    roc_curve, RocCurveDisplay, accuracy_score, precision_recall_fscore_support\n", ")\n", "\n", "from sklearn.linear_model import LogisticRegression\n", "from sklearn.ensemble import RandomForestClassifier, GradientBoostingClassifier\n", "from sklearn.svm import SVC\n", "from sklearn.neighbors import KNeighborsClassifier\n", "from sklearn.naive_bayes import GaussianNB\n", "from sklearn.neural_network import MLPClassifier\n", "\n", "import json\n", "import os\n", "\n", "pd.set_option('display.max_columns', None)"]}, {"cell_type": "markdown", "metadata": {}, "source": ["## Load Data"]}, {"cell_type": "code", "execution_count": null, "metadata": {}, "outputs": [], "source": ["# Option A: If you uploaded the dataset file in this notebook session, set its path here:\n", "csv_path = \"/mnt/data/churn_dataset.csv\"  # Replace with your uploaded file path if needed\n", "\n", "df = pd.read_csv(csv_path)\n", "print(\"Shape:\", df.shape)\n", "df.head()"]}, {"cell_type": "markdown", "metadata": {}, "source": ["## EDA: Overview & Cleaning Checks"]}, {"cell_type": "code", "execution_count": null, "metadata": {}, "outputs": [], "source": ["print(\"Data Types\\n\", df.dtypes)\n", "print(\"\\nMissing values per column:\\n\", df.isna().sum())\n", "print(\"\\nClass balance:\\n\", df['churn'].value_counts(normalize=True))\n", "\n", "# Basic stats for numeric columns\n", "display(df.describe(include='number'))\n", "\n", "# Categorical overview\n", "for c in df.select_dtypes(include=['object']).columns:\n", "    print(f\"\\nValue counts for {c}:\")\n", "    print(df[c].value_counts(dropna=False).head(10))\n", "\n", "# Correlation heatmap (numeric only)\n", "numeric_cols = df.select_dtypes(include=[np.number]).columns.tolist()\n", "plt.figure(figsize=(8,6))\n", "sns.heatmap(df[numeric_cols].corr(), annot=False)\n", "plt.title(\"Correlation Heatmap (Numeric)\")\n", "plt.show()\n", "\n", "# Distribution of target\n", "plt.figure(figsize=(5,4))\n", "df['churn'].value_counts().plot(kind='bar')\n", "plt.title(\"Target Distribution (churn)\")\n", "plt.xlabel(\"Class\")\n", "plt.ylabel(\"Count\")\n", "plt.show()"]}, {"cell_type": "markdown", "metadata": {}, "source": ["## Train/Test Split & Preprocessing"]}, {"cell_type": "code", "execution_count": null, "metadata": {}, "outputs": [], "source": ["X = df.drop(columns=['churn'])\n", "y = df['churn']\n", "\n", "numeric_features = X.select_dtypes(include=[np.number]).columns.tolist()\n", "categorical_features = X.select_dtypes(exclude=[np.number]).columns.tolist()\n", "\n", "numeric_transformer = Pipeline(steps=[\n", "    (\"imputer\", SimpleImputer(strategy=\"median\")),\n", "    (\"scaler\", StandardScaler())\n", "])\n", "\n", "categorical_transformer = Pipeline(steps=[\n", "    (\"imputer\", SimpleImputer(strategy=\"most_frequent\")),\n", "    (\"onehot\", OneHotEncoder(handle_unknown=\"ignore\"))\n", "])\n", "\n", "preprocess = ColumnTransformer(\n", "    transformers=[\n", "        (\"num\", numeric_transformer, numeric_features),\n", "        (\"cat\", categorical_transformer, categorical_features),\n", "    ]\n", ")\n", "\n", "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42, stratify=y)\n", "\n", "print(\"Train shape:\", X_train.shape, \" Test shape:\", X_test.shape)"]}, {"cell_type": "markdown", "metadata": {}, "source": ["## PCA (Visual Exploration)"]}, {"cell_type": "code", "execution_count": null, "metadata": {}, "outputs": [], "source": ["# We'll fit PCA on the preprocessed training data for visualization (2 components)\n", "pca_for_plot = Pipeline(steps=[\n", "    (\"preprocess\", preprocess),\n", "    (\"pca\", PCA(n_components=2, random_state=42))\n", "])\n", "\n", "X_train_pca2 = pca_for_plot.fit_transform(X_train)\n", "plt.figure(figsize=(6,5))\n", "plt.scatter(X_train_pca2[:,0], X_train_pca2[:,1], c=y_train, alpha=0.6)\n", "plt.title(\"PCA (2 Components) of Training Data\")\n", "plt.xlabel(\"PC1\")\n", "plt.ylabel(\"PC2\")\n", "plt.show()\n", "\n", "# Explained variance using a deeper PCA\n", "pca_exp = Pipeline(steps=[\n", "    (\"preprocess\", preprocess),\n", "    (\"pca\", PCA(n_components=10, random_state=42))\n", "])\n", "pca_exp.fit(X_train)\n", "explained = pca_exp.named_steps[\"pca\"].explained_variance_ratio_\n", "print(\"Explained variance ratio (first 10 PCs):\", np.round(explained, 4))\n", "plt.figure(figsize=(6,4))\n", "plt.plot(np.cumsum(explained), marker='o')\n", "plt.title(\"Cumulative Explained Variance (First 10 PCs)\")\n", "plt.xlabel(\"Number of Components\")\n", "plt.ylabel(\"Cumulative Variance Explained\")\n", "plt.grid(True)\n", "plt.show()"]}, {"cell_type": "markdown", "metadata": {}, "source": ["## Train Multiple Models & Evaluate"]}, {"cell_type": "code", "execution_count": null, "metadata": {}, "outputs": [], "source": ["models = {\n", "    \"LogisticRegression\": LogisticRegression(max_iter=500, n_jobs=None),\n", "    \"RandomForest\": RandomForestClassifier(n_estimators=300, random_state=42),\n", "    \"GradientBoosting\": GradientBoostingClassifier(random_state=42),\n", "    \"SVM_RBF\": SVC(kernel='rbf', probability=True, random_state=42),\n", "    \"KNN\": KNeighborsClassifier(n_neighbors=15),\n", "    \"NaiveBayes\": GaussianNB(),\n", "    \"MLP\": MLPClassifier(hidden_layer_sizes=(64,32), activation='relu', max_iter=300, random_state=42)\n", "}\n", "\n", "results = []\n", "probas = {}\n", "for name, clf in models.items():\n", "    pipe = Pipeline(steps=[(\"preprocess\", preprocess), (\"clf\", clf)])\n", "    pipe.fit(X_train, y_train)\n", "    y_pred = pipe.predict(X_test)\n", "    if hasattr(pipe.named_steps[\"clf\"], \"predict_proba\"):\n", "        y_score = pipe.predict_proba(X_test)[:,1]\n", "    else:\n", "        # fallback: decision function\n", "        if hasattr(pipe.named_steps[\"clf\"], \"decision_function\"):\n", "            dec = pipe.decision_function(X_test)\n", "            # scale to [0,1] via min-max for ROC\n", "            dec_min, dec_max = dec.min(), dec.max()\n", "            y_score = (dec - dec_min) / (dec_max - dec_min + 1e-9)\n", "        else:\n", "            # if no scores available, use predictions (degrades AUC meaningfully)\n", "            y_score = y_pred.astype(float)\n", "    auc = roc_auc_score(y_test, y_score)\n", "    acc = accuracy_score(y_test, y_pred)\n", "    prec, rec, f1, _ = precision_recall_fscore_support(y_test, y_pred, average=\"binary\", zero_division=0)\n", "    results.append({\"model\": name, \"AUC\": auc, \"Accuracy\": acc, \"Precision\": prec, \"Recall\": rec, \"F1\": f1})\n", "    probas[name] = y_score\n", "    print(f\"{name}: AUC={auc:.4f}, Acc={acc:.4f}, Prec={prec:.4f}, Rec={rec:.4f}, F1={f1:.4f}\")\n", "\n", "results_df = pd.DataFrame(results).sort_values(\"AUC\", ascending=False)\n", "results_df"]}, {"cell_type": "markdown", "metadata": {}, "source": ["## ROC Curves"]}, {"cell_type": "code", "execution_count": null, "metadata": {}, "outputs": [], "source": ["plt.figure(figsize=(7,6))\n", "for name, y_score in probas.items():\n", "    fpr, tpr, _ = roc_curve(y_test, y_score)\n", "    plt.plot(fpr, tpr, label=f\"{name}\")\n", "plt.plot([0,1], [0,1], linestyle='--')\n", "plt.xlabel(\"False Positive Rate\")\n", "plt.ylabel(\"True Positive Rate\")\n", "plt.title(\"ROC Curves (Binary Churn)\")\n", "plt.legend()\n", "plt.grid(True)\n", "plt.show()"]}, {"cell_type": "markdown", "metadata": {}, "source": ["## Pick Best Model by AUC & Save"]}, {"cell_type": "code", "execution_count": null, "metadata": {}, "outputs": [], "source": ["best = results_df.iloc[0]\n", "best_model_name = best['model']\n", "print(\"Best model:\", best_model_name)\n", "\n", "# Refit best model on full training data\n", "best_clf = models[best_model_name]\n", "best_pipe = Pipeline(steps=[(\"preprocess\", preprocess), (\"clf\", best_clf)])\n", "best_pipe.fit(X_train, y_train)\n", "\n", "# Export: classification report and confusion matrix\n", "y_pred_best = best_pipe.predict(X_test)\n", "print(\"\\nClassification Report (Best Model)\\n\")\n", "print(classification_report(y_test, y_pred_best))\n", "\n", "cm = confusion_matrix(y_test, y_pred_best)\n", "plt.figure(figsize=(5,4))\n", "sns.heatmap(cm, annot=True, fmt=\"d\")\n", "plt.title(f\"Confusion Matrix \u2014 {best_model_name}\")\n", "plt.xlabel(\"Predicted\")\n", "plt.ylabel(\"True\")\n", "plt.show()\n", "\n", "# Save results\n", "import joblib\n", "joblib.dump(best_pipe, \"best_churn_model.joblib\")\n", "results_df.to_csv(\"model_results.csv\", index=False)\n", "print(\"Saved best model to best_churn_model.joblib and metrics to model_results.csv\")"]}, {"cell_type": "markdown", "metadata": {}, "source": ["## Notes\n", "- You can toggle PCA as a preprocessing step by inserting it inside the pipeline before the classifier. In this notebook, we use PCA only for visualization to avoid losing too much signal.\n", "- Replace `csv_path` with the path to your dataset file if you upload it directly in Colab.\n", "- To reuse the trained pipeline: `joblib.load(\"best_churn_model.joblib\")` and call `.predict` or `.predict_proba`."]}], "metadata": {"kernelspec": {"display_name": "Python 3", "language": "python", "name": "python3"}, "language_info": {"name": "python", "version": "3.x"}}, "nbformat": 4, "nbformat_minor": 5}